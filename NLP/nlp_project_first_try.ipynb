{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_project_first_try.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN46SWBdeFERuV8Sc6bIl7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimisz/tensorflow_projects/blob/main/NLP/nlp_project_first_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGjDaJpmbN4Q",
        "outputId": "5fc30abc-c1fa-4573-f9aa-d23d31ee64d5"
      },
      "source": [
        "!pip install epub-conversion"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting epub-conversion\n",
            "  Downloading epub-conversion-1.0.15.tar.gz (6.5 kB)\n",
            "Collecting bz2file\n",
            "  Downloading bz2file-0.98.tar.gz (11 kB)\n",
            "Collecting epub\n",
            "  Downloading epub-0.5.2.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting ciseau\n",
            "  Downloading ciseau-1.0.1.tar.gz (10 kB)\n",
            "Building wheels for collected packages: epub-conversion, bz2file, ciseau, epub\n",
            "  Building wheel for epub-conversion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epub-conversion: filename=epub_conversion-1.0.15-py3-none-any.whl size=7368 sha256=37ee637317569217abfee6510ec44357e1fb06b89ca7acb496c09108d6094607\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/f9/95/1072882c3f236af4ab652dbbcdd72ef236572ebb3b9e3d1ff9\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6883 sha256=ed6db4f145d498bd0a789dbe7dc90684ca0f686ccaeed772608e78a543dac9af\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/ce/8d/b5f76b602b16a8a39f2ded74189cf5f09fc4a87bea16c54a8b\n",
            "  Building wheel for ciseau (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ciseau: filename=ciseau-1.0.1-py3-none-any.whl size=12236 sha256=dc60a03fce334974b777fe0ef0bde1d53e80ec1915eb0fb952b030f655261638\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/14/91/4389bfb49b84d9cd5d41fec124d5060e18439b42974ed19364\n",
            "  Building wheel for epub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epub: filename=epub-0.5.2-py3-none-any.whl size=16321 sha256=4f083c1a2a4bd4068cd196790c258a1963e83b445abdd75ec3d1a36e7251dbe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/09/b8/d961b2bd6ca0098a4dc36d342ab1e988837f6cced933630340\n",
            "Successfully built epub-conversion bz2file ciseau epub\n",
            "Installing collected packages: epub, ciseau, bz2file, epub-conversion\n",
            "Successfully installed bz2file-0.98 ciseau-1.0.1 epub-0.5.2 epub-conversion-1.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKOzd3y6b8gH",
        "outputId": "ef3ce2fc-b9ab-410a-b76d-c6bb910f9e49"
      },
      "source": [
        "!pip install xml_cleaner"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xml_cleaner\n",
            "  Downloading xml-cleaner-2.0.4.tar.gz (10 kB)\n",
            "Building wheels for collected packages: xml-cleaner\n",
            "  Building wheel for xml-cleaner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xml-cleaner: filename=xml_cleaner-2.0.4-py3-none-any.whl size=12141 sha256=1c41743b02737fe9e9c043e1752d7b1b359291c32df45a47cb4ca2dd81787fc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/3a/75/762392359b6e5c0be78269be3ed5b074a6e512e3f0883b0646\n",
            "Successfully built xml-cleaner\n",
            "Installing collected packages: xml-cleaner\n",
            "Successfully installed xml-cleaner-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUXxawHfbhE8"
      },
      "source": [
        "from epub_conversion.utils import open_book, convert_epub_to_lines\n",
        "\n",
        "book = open_book(\"/content/Robin Sharma Pack (10 Volume Set) by Robin Sharma (z-lib.org).epub\")\n",
        "\n",
        "lines = convert_epub_to_lines(book)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyWn8W-Vbw8k",
        "outputId": "151e2415-a13c-407a-b4da-cd834a8f31e9"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16866"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-7JZlWHcEtQ"
      },
      "source": [
        "#lines[:100]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dAt2ghkcPmd"
      },
      "source": [
        "# Function to strip the html tags\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    import re\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9odiYr9czis"
      },
      "source": [
        "text_as_list = [remove_html_tags(line) for line in lines]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9LiPEfmc_28"
      },
      "source": [
        "# delete the foreword\n",
        "text_as_list = text_as_list[128:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNf13fTsdDS7"
      },
      "source": [
        "text_as_string = \" \".join(text_as_list)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "oS31e6HBeFwO",
        "outputId": "4d7e8f95-0e83-4bad-97a4-a301e31b2ef7"
      },
      "source": [
        "text_as_string[:500]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CHAPTER ONE  The Wake-Up Call He collapsed right in the middle of a packed courtroom. He was one of this country’s most distinguished trial lawyers. He was also a man who was as well known for the three-thousand-dollar Italian suits that draped his well-fed frame as for his remarkable string of legal victories. I simply stood there, paralyzed by the shock of what I had just witnessed. The great Julian Mantle had been reduced to a victim and was now squirming on the ground like a helpless infant,'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEc-OdV0eUZG",
        "outputId": "01805209-8da0-435d-b76b-cbdf6b61a914"
      },
      "source": [
        "len(text_as_string)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2873591"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRyh5o16frmK"
      },
      "source": [
        "vocab = sorted(set(text_as_string))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mAr5MWnf2er",
        "outputId": "10795828-d606-4f30-8e43-ea2710e9bbbe"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2nfR26XgRSd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVgiA7GWf4T-"
      },
      "source": [
        "## Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx_spOcuf-CW"
      },
      "source": [
        "char_to_ind = {char: ind for ind, char in enumerate(vocab)}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebwUnK32gGKA",
        "outputId": "32b5d6c5-e9a2-401e-dda3-fa90631f85f3"
      },
      "source": [
        "char_to_ind['A']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANPfLqfagIN1"
      },
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6Tae9NMUgPSQ",
        "outputId": "4469ec25-05f2-4599-e1cd-bdee1c2a56b3"
      },
      "source": [
        "ind_to_char[30]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiEjY2Z4ggRE"
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text_as_string])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnJTdcWfgoUK",
        "outputId": "18f06c5a-5c1a-40bc-d2ef-be6470435dba"
      },
      "source": [
        "encoded_text.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2873591,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6cXtczgukJ"
      },
      "source": [
        "sample = text_as_string[:500]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "gRubGSMugz4E",
        "outputId": "e652bde2-2742-4d32-cc5e-8dbef2c76c1a"
      },
      "source": [
        "sample"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CHAPTER ONE  The Wake-Up Call He collapsed right in the middle of a packed courtroom. He was one of this country’s most distinguished trial lawyers. He was also a man who was as well known for the three-thousand-dollar Italian suits that draped his well-fed frame as for his remarkable string of legal victories. I simply stood there, paralyzed by the shock of what I had just witnessed. The great Julian Mantle had been reduced to a victim and was now squirming on the ground like a helpless infant,'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCXtvKdxg1Kx",
        "outputId": "302539d2-5e0f-4872-c995-18435fa496a2"
      },
      "source": [
        "encoded_text[:500]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 32,  37,  30,  45,  49,  34,  47,   0,  44,  43,  34,   0,   0,\n",
              "        49,  67,  64,   0,  52,  60,  70,  64,  12,  50,  75,   0,  32,\n",
              "        60,  71,  71,   0,  37,  64,   0,  62,  74,  71,  71,  60,  75,\n",
              "        78,  64,  63,   0,  77,  68,  66,  67,  79,   0,  68,  73,   0,\n",
              "        79,  67,  64,   0,  72,  68,  63,  63,  71,  64,   0,  74,  65,\n",
              "         0,  60,   0,  75,  60,  62,  70,  64,  63,   0,  62,  74,  80,\n",
              "        77,  79,  77,  74,  74,  72,  13,   0,  37,  64,   0,  82,  60,\n",
              "        78,   0,  74,  73,  64,   0,  74,  65,   0,  79,  67,  68,  78,\n",
              "         0,  62,  74,  80,  73,  79,  77,  84, 112,  78,   0,  72,  74,\n",
              "        78,  79,   0,  63,  68,  78,  79,  68,  73,  66,  80,  68,  78,\n",
              "        67,  64,  63,   0,  79,  77,  68,  60,  71,   0,  71,  60,  82,\n",
              "        84,  64,  77,  78,  13,   0,  37,  64,   0,  82,  60,  78,   0,\n",
              "        60,  71,  78,  74,   0,  60,   0,  72,  60,  73,   0,  82,  67,\n",
              "        74,   0,  82,  60,  78,   0,  60,  78,   0,  82,  64,  71,  71,\n",
              "         0,  70,  73,  74,  82,  73,   0,  65,  74,  77,   0,  79,  67,\n",
              "        64,   0,  79,  67,  77,  64,  64,  12,  79,  67,  74,  80,  78,\n",
              "        60,  73,  63,  12,  63,  74,  71,  71,  60,  77,   0,  38,  79,\n",
              "        60,  71,  68,  60,  73,   0,  78,  80,  68,  79,  78,   0,  79,\n",
              "        67,  60,  79,   0,  63,  77,  60,  75,  64,  63,   0,  67,  68,\n",
              "        78,   0,  82,  64,  71,  71,  12,  65,  64,  63,   0,  65,  77,\n",
              "        60,  72,  64,   0,  60,  78,   0,  65,  74,  77,   0,  67,  68,\n",
              "        78,   0,  77,  64,  72,  60,  77,  70,  60,  61,  71,  64,   0,\n",
              "        78,  79,  77,  68,  73,  66,   0,  74,  65,   0,  71,  64,  66,\n",
              "        60,  71,   0,  81,  68,  62,  79,  74,  77,  68,  64,  78,  13,\n",
              "         0,  38,   0,  78,  68,  72,  75,  71,  84,   0,  78,  79,  74,\n",
              "        74,  63,   0,  79,  67,  64,  77,  64,  11,   0,  75,  60,  77,\n",
              "        60,  71,  84,  85,  64,  63,   0,  61,  84,   0,  79,  67,  64,\n",
              "         0,  78,  67,  74,  62,  70,   0,  74,  65,   0,  82,  67,  60,\n",
              "        79,   0,  38,   0,  67,  60,  63,   0,  69,  80,  78,  79,   0,\n",
              "        82,  68,  79,  73,  64,  78,  78,  64,  63,  13,   0,  49,  67,\n",
              "        64,   0,  66,  77,  64,  60,  79,   0,  39,  80,  71,  68,  60,\n",
              "        73,   0,  42,  60,  73,  79,  71,  64,   0,  67,  60,  63,   0,\n",
              "        61,  64,  64,  73,   0,  77,  64,  63,  80,  62,  64,  63,   0,\n",
              "        79,  74,   0,  60,   0,  81,  68,  62,  79,  68,  72,   0,  60,\n",
              "        73,  63,   0,  82,  60,  78,   0,  73,  74,  82,   0,  78,  76,\n",
              "        80,  68,  77,  72,  68,  73,  66,   0,  74,  73,   0,  79,  67,\n",
              "        64,   0,  66,  77,  74,  80,  73,  63,   0,  71,  68,  70,  64,\n",
              "         0,  60,   0,  67,  64,  71,  75,  71,  64,  78,  78,   0,  68,\n",
              "        73,  65,  60,  73,  79,  11])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb2L_9Rlg4hV"
      },
      "source": [
        "## Creating Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "TBw-35M2g-VT",
        "outputId": "419db86e-754c-4caa-951a-9478ef8ab26f"
      },
      "source": [
        "text_as_string[:1000]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CHAPTER ONE  The Wake-Up Call He collapsed right in the middle of a packed courtroom. He was one of this country’s most distinguished trial lawyers. He was also a man who was as well known for the three-thousand-dollar Italian suits that draped his well-fed frame as for his remarkable string of legal victories. I simply stood there, paralyzed by the shock of what I had just witnessed. The great Julian Mantle had been reduced to a victim and was now squirming on the ground like a helpless infant, shaking and shivering and sweating like a maniac. Everything seemed to move in slow motion from that point on. “My God, Julian’s in trouble!” his paralegal screamed, emotionally offering us a blinding glimpse of the obvious. The judge looked panic-stricken and quickly muttered something into the private phone she had had installed in the event of an emergency. As for me, I could only stand there, dazed and confused. Please don’t die, you old fool. It’s too early for you to check out. You don’t '"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q0z1vyMhCWi"
      },
      "source": [
        "seq_len = 200"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnlNHYlIhN4-"
      },
      "source": [
        "total_num_seq = len(text_as_string) // (seq_len + 1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R2Q5PjVhVER",
        "outputId": "e0347f79-992b-4f1d-b69b-0aba6d178f05"
      },
      "source": [
        "total_num_seq"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14296"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPtJPjthXVU"
      },
      "source": [
        "## Prepare Dataset using Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccF_kTYIhfxR"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycv-79wZhmG6",
        "outputId": "ef4d21e9-d1cd-4424-9683-f3bdb838feef"
      },
      "source": [
        "type(char_dataset)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21dAYkZwhoER"
      },
      "source": [
        "sequences = char_dataset.batch(seq_len + 1, drop_remainder=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgcpRJoahymU"
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "  input_txt = seq[:-1] # Hello my nam\n",
        "  target_txt = seq[1:] # ello my name\n",
        "  return input_txt, target_txt"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imx9Hn02h1wC"
      },
      "source": [
        "# map the function to all the sequences\n",
        "dataset = sequences.map(create_seq_targets)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4fDK4GGh6aL",
        "outputId": "908db62c-2369-472a-ebec-6d5a2d772a4e"
      },
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        "  print(input_txt.numpy())\n",
        "  print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
        "  print(\"\\n\")\n",
        "  print(target_txt.numpy())\n",
        "  print(\"\".join(ind_to_char[target_txt.numpy()]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 32  37  30  45  49  34  47   0  44  43  34   0   0  49  67  64   0  52\n",
            "  60  70  64  12  50  75   0  32  60  71  71   0  37  64   0  62  74  71\n",
            "  71  60  75  78  64  63   0  77  68  66  67  79   0  68  73   0  79  67\n",
            "  64   0  72  68  63  63  71  64   0  74  65   0  60   0  75  60  62  70\n",
            "  64  63   0  62  74  80  77  79  77  74  74  72  13   0  37  64   0  82\n",
            "  60  78   0  74  73  64   0  74  65   0  79  67  68  78   0  62  74  80\n",
            "  73  79  77  84 112  78   0  72  74  78  79   0  63  68  78  79  68  73\n",
            "  66  80  68  78  67  64  63   0  79  77  68  60  71   0  71  60  82  84\n",
            "  64  77  78  13   0  37  64   0  82  60  78   0  60  71  78  74   0  60\n",
            "   0  72  60  73   0  82  67  74   0  82  60  78   0  60  78   0  82  64\n",
            "  71  71   0  70  73  74  82  73   0  65  74  77   0  79  67  64   0  79\n",
            "  67  77]\n",
            "CHAPTER ONE  The Wake-Up Call He collapsed right in the middle of a packed courtroom. He was one of this country’s most distinguished trial lawyers. He was also a man who was as well known for the thr\n",
            "\n",
            "\n",
            "[ 37  30  45  49  34  47   0  44  43  34   0   0  49  67  64   0  52  60\n",
            "  70  64  12  50  75   0  32  60  71  71   0  37  64   0  62  74  71  71\n",
            "  60  75  78  64  63   0  77  68  66  67  79   0  68  73   0  79  67  64\n",
            "   0  72  68  63  63  71  64   0  74  65   0  60   0  75  60  62  70  64\n",
            "  63   0  62  74  80  77  79  77  74  74  72  13   0  37  64   0  82  60\n",
            "  78   0  74  73  64   0  74  65   0  79  67  68  78   0  62  74  80  73\n",
            "  79  77  84 112  78   0  72  74  78  79   0  63  68  78  79  68  73  66\n",
            "  80  68  78  67  64  63   0  79  77  68  60  71   0  71  60  82  84  64\n",
            "  77  78  13   0  37  64   0  82  60  78   0  60  71  78  74   0  60   0\n",
            "  72  60  73   0  82  67  74   0  82  60  78   0  60  78   0  82  64  71\n",
            "  71   0  70  73  74  82  73   0  65  74  77   0  79  67  64   0  79  67\n",
            "  77  64]\n",
            "HAPTER ONE  The Wake-Up Call He collapsed right in the middle of a packed courtroom. He was one of this country’s most distinguished trial lawyers. He was also a man who was as well known for the thre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJWzm2coh96Y"
      },
      "source": [
        "### Generating Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbayV-uZiG-H"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CTJGj43iJNx"
      },
      "source": [
        "buffer_size = 10000"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WGzqWeBiLnn"
      },
      "source": [
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu7gAbvjiWcR",
        "outputId": "d8fe289e-9121-4036-f69a-90c00f73a8fb"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 200), (128, 200)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivk1FrY0iYTC"
      },
      "source": [
        "## Create a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IfctssiejK"
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdHu_UT5ihS1",
        "outputId": "525c0066-1e20-4aec-bfa4-857368e7f1e7"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-VeWlRUijAO"
      },
      "source": [
        "embed_dim = 64\n",
        "rnn_neurons = 1026"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HV28WcMip5K"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljrLqFh2ixES"
      },
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true,\n",
        "                                         y_pred,\n",
        "                                         from_logits=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEijufa4i_Nz"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBsp8xVjJc5"
      },
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
        "  model.add(GRU(rnn_neurons, \n",
        "                return_sequences=True, \n",
        "                stateful=True, \n",
        "                recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "\n",
        "  model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "040ZQ0s_jQIc"
      },
      "source": [
        "model = create_model(vocab_size=vocab_size,\n",
        "                     embed_dim=embed_dim,\n",
        "                     rnn_neurons=rnn_neurons,\n",
        "                     batch_size=batch_size)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1uvPDGAjS0I",
        "outputId": "c4bf903c-a4ca-4688-d09f-2ff023aebf0e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           7616      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 119)          122213    \n",
            "=================================================================\n",
            "Total params: 3,491,005\n",
            "Trainable params: 3,491,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOZPbLyEjk7u",
        "outputId": "1cbb86aa-d810-4347-a464-0dd26b21f0d6"
      },
      "source": [
        "model.fit(dataset, epochs=40)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "111/111 [==============================] - 55s 418ms/step - loss: 3.1868\n",
            "Epoch 2/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 2.3412\n",
            "Epoch 3/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 2.0946\n",
            "Epoch 4/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 1.8466\n",
            "Epoch 5/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 1.6373\n",
            "Epoch 6/40\n",
            "111/111 [==============================] - 50s 424ms/step - loss: 1.4870\n",
            "Epoch 7/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 1.3866\n",
            "Epoch 8/40\n",
            "111/111 [==============================] - 50s 424ms/step - loss: 1.3157\n",
            "Epoch 9/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 1.2634\n",
            "Epoch 10/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 1.2214\n",
            "Epoch 11/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 1.1869\n",
            "Epoch 12/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 1.1568\n",
            "Epoch 13/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 1.1302\n",
            "Epoch 14/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 1.1064\n",
            "Epoch 15/40\n",
            "111/111 [==============================] - 50s 420ms/step - loss: 1.0838\n",
            "Epoch 16/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 1.0626\n",
            "Epoch 17/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 1.0410\n",
            "Epoch 18/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 1.0224\n",
            "Epoch 19/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 1.0027\n",
            "Epoch 20/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 0.9844\n",
            "Epoch 21/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 0.9650\n",
            "Epoch 22/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.9468\n",
            "Epoch 23/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.9280\n",
            "Epoch 24/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.9095\n",
            "Epoch 25/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.8912\n",
            "Epoch 26/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.8739\n",
            "Epoch 27/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 0.8560\n",
            "Epoch 28/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.8390\n",
            "Epoch 29/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 0.8224\n",
            "Epoch 30/40\n",
            "111/111 [==============================] - 50s 424ms/step - loss: 0.8063\n",
            "Epoch 31/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.7914\n",
            "Epoch 32/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.7766\n",
            "Epoch 33/40\n",
            "111/111 [==============================] - 50s 421ms/step - loss: 0.7623\n",
            "Epoch 34/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 0.7492\n",
            "Epoch 35/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 0.7368\n",
            "Epoch 36/40\n",
            "111/111 [==============================] - 50s 423ms/step - loss: 0.7263\n",
            "Epoch 37/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.7167\n",
            "Epoch 38/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.7067\n",
            "Epoch 39/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.6975\n",
            "Epoch 40/40\n",
            "111/111 [==============================] - 50s 422ms/step - loss: 0.6899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f945de46e90>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoO4vqpIjtkF"
      },
      "source": [
        "model.save(\"successful_success.h5\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvOVVqEY-Aea"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYRCUwn-Glv"
      },
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights(\"/content/successful_success.h5\")\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs9Vmxn4-p8x",
        "outputId": "2bea1c42-0525-40a8-e2b2-5bda70d11c2e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 64)             7616      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 119)            122213    \n",
            "=================================================================\n",
            "Total params: 3,491,005\n",
            "Trainable params: 3,491,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sFnJPoi-sAD"
      },
      "source": [
        "def generate_text(model, start_seed, gen_size=500, temp=1.0):\n",
        "  \n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "  text_generated = []\n",
        "  temperature = temp\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictionns = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(ind_to_char[predicted_id])\n",
        "  \n",
        "  return (start_seed + \"\".join(text_generated))\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jup3vgYK-6wa",
        "outputId": "fe87db27-c8b8-46c2-ca5a-a64c1681cb48"
      },
      "source": [
        "print(generate_text(model, \"said\", gen_size=2000))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saide to his keep me guidant. I get into sticky or the weaknesses of our lives. What he thinks our dreams for you to stick to the next level of appearing regrot. Rather than looking for the rest of your life so that they need to be polish and completely offered by a story that phavends generally planned from a per store for you. I won't another know Julian precisely. “And the driver had been, you are too young?’ heeps he ors, even though I took out a weekly simple lit. “I know I want you to brance a victim that rested in the city and I knew that, then considered, elevate another spectacularly hour end. Much of Milfroom is precisely where it was more production.   Of Mr Mead and had placed with settlement, pen Heaven. Then I saw at the lessons the timeline. I couldn’t help out. All the sages we truly are setting up our destinies and revitalizes that near for we’s or act of someone who desires to allow themselves to be recognized through someday, or interesting insight, stopping, softly underging and fell completely openind. Dah, the gorgest of all the superstar bo has something that was quicken historyourself it will focus on an one final extraordinary and body and pay huge divine person who dreamt crash. When you feel special when you know something If you have not become an excellent commitment to serenity and review your counterpreps on a plane to be bend in the direction of your body,’ said is not the full colothe bottle of your life that will ready to change our lives. Become an eyseemize you leave the process of wisdom that has happened to you in the seemingly excellent teachers. Those judgment makes life better. When I learned of being aware of the power of leadership, help them for the red and by learning and deepens. The figst flying habit, meaningful rap, cracks, leaving your true potential for the talents and professional effectiveness on the white of what the world rejoice spend their business in all important abindo important is all about.” “I can’t see anyo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ-OxXaM_FUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}